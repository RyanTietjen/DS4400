{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdd8fb3",
   "metadata": {},
   "source": [
    "Professor Wu\n",
    "\n",
    "DS 4400: Machine Learning I\n",
    "\n",
    "Ryan Tietjen\n",
    "\n",
    "9/8/24\n",
    "\n",
    "**Assignment 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59921a18",
   "metadata": {},
   "source": [
    "## **Question 1.** Assume that $x$ is a scalar variable, find the derivative by hand for the following functions, and then use Python to confirm your answer.\n",
    "\n",
    "## 1. $f(x) = 2x^2 + 1$\n",
    "\n",
    "Using the power and constant rules:\n",
    "\n",
    "$\\frac{d}{dx} 2x^2 + 1 = 4x + 0 = \\boxed{4x}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d73db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd.numpy import log\n",
    "from autograd.numpy import exp\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384b283c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: 1.829, Theoretical gradient: 1.829\n",
      "Auto gradient: 2.823, Theoretical gradient: 2.823\n",
      "Auto gradient: 3.455, Theoretical gradient: 3.455\n",
      "Auto gradient: 0.765, Theoretical gradient: 0.765\n",
      "Auto gradient: -2.626, Theoretical gradient: -2.626\n",
      "Auto gradient: -2.387, Theoretical gradient: -2.387\n",
      "Auto gradient: 0.798, Theoretical gradient: 0.798\n",
      "Auto gradient: -3.255, Theoretical gradient: -3.255\n",
      "Auto gradient: -1.086, Theoretical gradient: -1.086\n",
      "Auto gradient: 6.202, Theoretical gradient: 6.202\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return 2 * x**2 + 1\n",
    "\n",
    "def dx_f(x):\n",
    "    return 4 * x\n",
    "\n",
    "auto_grad = grad(f)\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()\n",
    "    print(f\"Auto gradient: {auto_grad(x):.3f}, Theoretical gradient: {dx_f(x):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed2ad85",
   "metadata": {},
   "source": [
    "## 2. $f(x) = e^{x^2}$\n",
    "\n",
    "Let $ g = x^2$\n",
    "\n",
    "Then, $f(x) = e^{g}$\n",
    "\n",
    "So, $\\frac{df}{dg} = e^g$ and $\\frac{dg}{dx} = 2x$\n",
    "\n",
    "$\\frac{df}{dg} \\frac{dg}{dx} = e^g \\cdot 2x = \\boxed{2x\\cdot e^{x^2}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e316da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: 1.427, Theoretical gradient: 1.427\n",
      "Auto gradient: -4.012, Theoretical gradient: -4.012\n",
      "Auto gradient: 0.186, Theoretical gradient: 0.186\n",
      "Auto gradient: 0.814, Theoretical gradient: 0.814\n",
      "Auto gradient: 11.570, Theoretical gradient: 11.570\n",
      "Auto gradient: -4.279, Theoretical gradient: -4.279\n",
      "Auto gradient: 0.632, Theoretical gradient: 0.632\n",
      "Auto gradient: -7.807, Theoretical gradient: -7.807\n",
      "Auto gradient: 5.320, Theoretical gradient: 5.320\n",
      "Auto gradient: 9.946, Theoretical gradient: 9.946\n"
     ]
    }
   ],
   "source": [
    "def f2(x):\n",
    "    return np.exp(x**2)\n",
    "\n",
    "def dx_f2(x):\n",
    "    return 2 * x * np.exp(x**2)\n",
    "\n",
    "auto_grad = grad(f2)\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()\n",
    "    print(f\"Auto gradient: {auto_grad(x):.3f}, Theoretical gradient: {dx_f2(x):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4d36ab",
   "metadata": {},
   "source": [
    "## 3. $f(x) = (3x - 2)^2$\n",
    "\n",
    "Let $g = 3x-2$\n",
    "\n",
    "Then, $f(x) = g^2$\n",
    "\n",
    "So, $\\frac{df}{dg} = 2g$ and $\\frac{dg}{dx} = 3$\n",
    "\n",
    "$\\frac{df}{dg} \\frac{dg}{dx} = 2g \\cdot 3 = \\boxed{6(3x-2)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff97c2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: -18.862, Theoretical gradient: -18.862\n",
      "Auto gradient: -14.800, Theoretical gradient: -14.800\n",
      "Auto gradient: -38.579, Theoretical gradient: -38.579\n",
      "Auto gradient: 13.088, Theoretical gradient: 13.088\n",
      "Auto gradient: -9.360, Theoretical gradient: -9.360\n",
      "Auto gradient: -10.007, Theoretical gradient: -10.007\n",
      "Auto gradient: -6.952, Theoretical gradient: -6.952\n",
      "Auto gradient: -32.711, Theoretical gradient: -32.711\n",
      "Auto gradient: -13.236, Theoretical gradient: -13.236\n",
      "Auto gradient: -6.711, Theoretical gradient: -6.711\n"
     ]
    }
   ],
   "source": [
    "def f3(x):\n",
    "    return (3*x-2)**2\n",
    "\n",
    "def dx_f3(x):\n",
    "    return 6 * (3*x-2)\n",
    "\n",
    "auto_grad = grad(f3)\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()\n",
    "    print(f\"Auto gradient: {auto_grad(x):.3f}, Theoretical gradient: {dx_f3(x):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303520c",
   "metadata": {},
   "source": [
    "## 4. $f(x) = \\sum_{i=1}^n (3x - y_i)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ec404",
   "metadata": {},
   "source": [
    "Let $g = 3x - y_i$\n",
    "\n",
    "Then, $f(x) = \\sum_{i=1}^n g^2$\n",
    "\n",
    "So, $\\frac{df}{dg} = 2g$ and $\\frac{dg}{dx} = 3$\n",
    "\n",
    "$\\frac{df}{dg} \\frac{dg}{dx} = 6g = 6(3x- y_i)$\n",
    "\n",
    "$\\frac{df}{dx} = \\boxed{6 \\cdot \\sum_{i=1}^n (3x - y_i)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2894d643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: -21.556, Theoretical gradient: -21.556\n",
      "Auto gradient: -45.581, Theoretical gradient: -45.581\n",
      "Auto gradient: -81.366, Theoretical gradient: -81.366\n",
      "Auto gradient: 55.899, Theoretical gradient: 55.899\n",
      "Auto gradient: -51.866, Theoretical gradient: -51.866\n",
      "Auto gradient: -11.236, Theoretical gradient: -11.236\n",
      "Auto gradient: 68.109, Theoretical gradient: 68.109\n",
      "Auto gradient: 19.127, Theoretical gradient: 19.127\n",
      "Auto gradient: 49.673, Theoretical gradient: 49.673\n",
      "Auto gradient: 49.670, Theoretical gradient: 49.670\n"
     ]
    }
   ],
   "source": [
    "def f4(x, y):\n",
    "    return np.sum((3*x - y)**2)\n",
    "\n",
    "def dx_f4(x, y):\n",
    "    return 6 * np.sum(3*x - y)\n",
    "\n",
    "auto_grad = grad(f4)\n",
    "\n",
    "y_values = np.array([np.random.randn(), np.random.randn(), np.random.randn()])\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()  # Generate a random x value\n",
    "    print(f\"Auto gradient: {auto_grad(x, y_values):.3f}, Theoretical gradient: {dx_f4(x, y_values):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7728165",
   "metadata": {},
   "source": [
    "## 5. $f(x) = log_2(\\frac{1}{x})$\n",
    "\n",
    "$log_2(\\frac{1}{x}) = log_2(x^{-1}) = -log_2(x)$\n",
    "\n",
    "$\\frac{d}{dx} -log_2(x) = \\frac{d}{dx} \\frac{-ln(x)}{ln(2)} = \\frac{-1}{ln(2)} (\\frac{d}{dx} ln(x)) = \\frac{-1}{ln(2)} \\cdot \\frac{1}{x} = \\boxed{\\frac{-1}{x \\cdot ln(2)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98f289bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: -1.181, Theoretical gradient: -1.181\n",
      "Auto gradient: 49.556, Theoretical gradient: 49.556\n",
      "Auto gradient: 3.961, Theoretical gradient: 3.961\n",
      "Auto gradient: -3.638, Theoretical gradient: -3.638\n",
      "Auto gradient: -1.415, Theoretical gradient: -1.415\n",
      "Auto gradient: 2.639, Theoretical gradient: 2.639\n",
      "Auto gradient: 5.078, Theoretical gradient: 5.078\n",
      "Auto gradient: -4.398, Theoretical gradient: -4.398\n",
      "Auto gradient: -1.636, Theoretical gradient: -1.636\n",
      "Auto gradient: 9.651, Theoretical gradient: 9.651\n"
     ]
    }
   ],
   "source": [
    "def f5(x):\n",
    "    return (log(1 / x)) / log(2)\n",
    "\n",
    "def dx_f5(x):\n",
    "    return -1/(x * log(2))\n",
    "\n",
    "auto_grad = grad(f5)\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()\n",
    "    print(f\"Auto gradient: {auto_grad(x):.3f}, Theoretical gradient: {dx_f5(x):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c455ea",
   "metadata": {},
   "source": [
    "## 6. $f(x) = log_2((x-2)^2)$\n",
    "\n",
    "$log_2((x-2)^2) = 2 \\cdot log_2(x-2) = \\frac{2 ln(x-2)}{ln 2} = \\frac{2}{ln(2)} \\cdot \\frac{d}{dx} ln(x-2) = \\frac{2}{ln(2)} \\cdot \\frac{1}{x-2} = \\boxed{\\frac{2}{ln(2) \\cdot (x-2)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c0c439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto gradient: -0.847, Theoretical gradient: -0.847\n",
      "Auto gradient: -2.754, Theoretical gradient: -2.754\n",
      "Auto gradient: -1.386, Theoretical gradient: -1.386\n",
      "Auto gradient: -1.919, Theoretical gradient: -1.919\n",
      "Auto gradient: -1.457, Theoretical gradient: -1.457\n",
      "Auto gradient: -1.729, Theoretical gradient: -1.729\n",
      "Auto gradient: -1.112, Theoretical gradient: -1.112\n",
      "Auto gradient: -1.442, Theoretical gradient: -1.442\n",
      "Auto gradient: -1.756, Theoretical gradient: -1.756\n",
      "Auto gradient: -2.137, Theoretical gradient: -2.137\n"
     ]
    }
   ],
   "source": [
    "def f6(x):\n",
    "    return (log((x-2)**2)) / log(2)\n",
    "\n",
    "def dx_f6(x):\n",
    "    return 2/((x-2) * log(2))\n",
    "\n",
    "auto_grad = grad(f6)\n",
    "\n",
    "for i in range(10):\n",
    "    x = np.random.randn()\n",
    "    print(f\"Auto gradient: {auto_grad(x):.3f}, Theoretical gradient: {dx_f6(x):.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd793ea",
   "metadata": {},
   "source": [
    "## Question 2. Solve the following integral problems by hand and then use python to confirm your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2ce5f8",
   "metadata": {},
   "source": [
    "## 1. $\\int_0^1 2x^2 + 1 dx $\n",
    "\n",
    "$F(x) = \\frac{2}{3}x^3 + x$\n",
    "\n",
    "$F(1) = \\frac{2}{3}1^3 + 1 = \\frac{5}{3}$\n",
    "\n",
    "$F(0) = \\frac{2}{3}0^3 + 0 = 0$\n",
    "\n",
    "$F(1) - F(0) = \\boxed{\\frac{5}{3}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "503e3103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 1.67\n"
     ]
    }
   ],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def f6(x):\n",
    "    return 2*x**2 + 1\n",
    "\n",
    "A, err =  quad(f6, 0 , 1)\n",
    "print(f\"Area = {A:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ae88ed",
   "metadata": {},
   "source": [
    "## 2. $\\int_0^1 e^x dx $\n",
    "\n",
    "$F(x) = e^x$\n",
    "\n",
    "$F(1) = e^1 = e$\n",
    "\n",
    "$F(0) = e^0 = 1$\n",
    "\n",
    "$F(1)-F(0) = \\boxed{e-1 \\approx 1.718}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69ff73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 1.718\n"
     ]
    }
   ],
   "source": [
    "def f7(x):\n",
    "    return np.exp(x)\n",
    "\n",
    "A, err =  quad(f7, 0 , 1)\n",
    "print(f\"Area = {A:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c90663",
   "metadata": {},
   "source": [
    "## 3. $\\int_0^1 (3x-2)^2 dx $\n",
    "\n",
    "$(3x-2)(3x-2) = 9x^2 - 12x + 4$\n",
    "\n",
    "$\\int 9x^2dx = 3x^3$\n",
    "\n",
    "$\\int -12xdx = -6x^2$\n",
    "\n",
    "$\\int 4dx = 4x$\n",
    "\n",
    "$F(x) = \\int_0^1 (3x-2)^2 dx = \\int_0^1 9x^2 -12x + 4 dx = {3x^3-6x^2+4x}$\n",
    "\n",
    "$F(1) = 3(1)^3-6(1)^2+4(1) = 1$\n",
    "\n",
    "$F(0) = 3(0)^3-6(0)^2+4(0) = 0$\n",
    "\n",
    "$F(1) - F(0) = \\boxed{1}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3c9cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 1.000\n"
     ]
    }
   ],
   "source": [
    "def f8(x):\n",
    "    return (3*x-2)**2\n",
    "\n",
    "A, err =  quad(f8, 0 , 1)\n",
    "print(f\"Area = {A:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39350bad",
   "metadata": {},
   "source": [
    "## 4. $\\int_0^1 e^{-x} + 2x + 1dx $\n",
    "\n",
    "$\\int e^{-x}dx = -e^{-x}$\n",
    "\n",
    "$\\int 2xdx = x^2$\n",
    "\n",
    "$\\int 1dx = 1x$\n",
    "\n",
    "$F(x) = \\int_0^1 e^{-x} + 2x + 1dx = -e^{-x} + x^2 + x$\n",
    "\n",
    "$F(1) = \\frac{1}{-e} + 1^2 + 1 = 2 - \\frac{1}{e}$\n",
    "\n",
    "$F(0) = -e^0 + 0^2 + 0 = -1$\n",
    "\n",
    "$F(1) - F(0) = 2 - \\frac{1}{e} - (-1) = \\boxed{3 - \\frac{1}{e} \\approx 2.632}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa59c16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area = 2.632\n"
     ]
    }
   ],
   "source": [
    "def f9(x):\n",
    "    return np.exp(-x) + 2*x + 1\n",
    "\n",
    "A, err =  quad(f9, 0 , 1)\n",
    "print(f\"Area = {A:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d080f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
